{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import pandas as pd\n",
        "\n",
        "import math\n",
        "import scipy\n",
        "import time\n",
        "from scipy import special\n",
        "from scipy import linalg\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "from sklearn.metrics import brier_score_loss, log_loss, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import argparse\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.utils.data import DataLoader, DistributedSampler\n",
        "\n",
        "import functools\n",
        "import itertools\n",
        "import operator\n",
        "import os"
      ],
      "metadata": {
        "id": "WFgzx1mrFdID"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "# turn on cuDNN autotuner if your input sizes are fixed\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
        "# for i in range(torch.cuda.device_count()):\n",
        "#     print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
      ],
      "metadata": {
        "id": "O-pjVZZQFZUi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Pep2Prob Dataset**"
      ],
      "metadata": {
        "id": "ZGeqJS6VHiyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "# Load Data\n",
        "#############################################\n",
        "\n",
        "precursor_info_path = '/content/drive/MyDrive/Mass Spectrum Prediction/data_May5/precursor_info.tsv'\n",
        "matrix_path = '/content/drive/MyDrive/Mass Spectrum Prediction/data_May5/matrix_mz_prob_mean_var.npy'\n",
        "train_test_split_path0 = '/content/drive/MyDrive/Mass Spectrum Prediction/data_May5/train_test_split_set_0.npy'\n",
        "\n",
        "precursor_df = pd.read_csv(precursor_info_path, sep='\\t')\n",
        "# each row is a precursor, which is a pair of (peptide_sequence, charge)\n",
        "# columns: [\n",
        "#   'precursor_index',          # corresponds to the index of the first order of the matrix\n",
        "#   'sequence',                 # peptide sequence, no modification by now\n",
        "#   'charge',                   # charge of the precursor\n",
        "#   'num_PSMs'                  # number of spectra that associated with this precursor\n",
        "# ]\n",
        "\n",
        "matrix = np.load(matrix_path)\n",
        "# matrix is a 3D numpy array with shape (num_precursors, num_tokens_to_predict, 4)\n",
        "#   num_precursors: the ith precursor corresponds to the ith row in precursor_df\n",
        "#   num_tokens_to_predict: the number of tokens (peak) to predict in the ith precursor\n",
        "#   4: for each token, there are 4 values: [\n",
        "#       \"m/z\",                  # the m/z value of the token (peak)\n",
        "#       \"probability\",          # the probability of the token (peak) to be observed\n",
        "#       \"mean_intensity\",       # the mean intensity of the token (peak)\n",
        "#       \"var_intensity\"         # the variance of the intensity of the token (peak)\n",
        "\n",
        "train_test_split_set = np.load(train_test_split_path0, allow_pickle=True).item()\n",
        "\n",
        "all_amino_acids = set(''.join(precursor_df['sequence'].tolist()))\n",
        "amino_acids = sorted(list(all_amino_acids))\n",
        "print(amino_acids)\n",
        "len(precursor_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxYxsAhPFZRG",
        "outputId": "a0ca82c9-08c0-4920-af80-6e057a19738b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "610117"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precursor_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "P7TaSbLTFZG_",
        "outputId": "fecaf864-d106-464a-e266-fef37104a444"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        precursor_index                       sequence  charge  num_PSMs  \\\n",
              "0                     0         AAAAAAAAAAAAAAAGAGAGAK       2      1151   \n",
              "1                     1          AAAAAAAAAAAAAAAASAGGK       2        25   \n",
              "2                     2          AAAAAAAAAAAAAAAASAGGK       3        29   \n",
              "3                     3         AAAAAAAAAAAAAAAGAGAGAK       3      1736   \n",
              "4                     4  AAAAAAAAAAAAAAATAASAAASAILGGR       3        65   \n",
              "...                 ...                            ...     ...       ...   \n",
              "610112           610112                    YYYWAVNPQDR       2       207   \n",
              "610113           610113                         YYYYER       2        48   \n",
              "610114           610114                         YYYYHR       3       517   \n",
              "610115           610115                        YYYYMWK       2        38   \n",
              "610116           610116                       YYYYWHLR       3        16   \n",
              "\n",
              "        sequence_length  original_precursor_index  \n",
              "0                    22                         0  \n",
              "1                    21                         1  \n",
              "2                    21                         2  \n",
              "3                    22                         3  \n",
              "4                    29                         4  \n",
              "...                 ...                       ...  \n",
              "610112               11                    632069  \n",
              "610113                6                    632070  \n",
              "610114                6                    632071  \n",
              "610115                7                    632072  \n",
              "610116                8                    632073  \n",
              "\n",
              "[610117 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2fdf9bd-b55c-4755-b2b5-636824fa8e54\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precursor_index</th>\n",
              "      <th>sequence</th>\n",
              "      <th>charge</th>\n",
              "      <th>num_PSMs</th>\n",
              "      <th>sequence_length</th>\n",
              "      <th>original_precursor_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AAAAAAAAAAAAAAAGAGAGAK</td>\n",
              "      <td>2</td>\n",
              "      <td>1151</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AAAAAAAAAAAAAAAASAGGK</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AAAAAAAAAAAAAAAASAGGK</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AAAAAAAAAAAAAAAGAGAGAK</td>\n",
              "      <td>3</td>\n",
              "      <td>1736</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AAAAAAAAAAAAAAATAASAAASAILGGR</td>\n",
              "      <td>3</td>\n",
              "      <td>65</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610112</th>\n",
              "      <td>610112</td>\n",
              "      <td>YYYWAVNPQDR</td>\n",
              "      <td>2</td>\n",
              "      <td>207</td>\n",
              "      <td>11</td>\n",
              "      <td>632069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610113</th>\n",
              "      <td>610113</td>\n",
              "      <td>YYYYER</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>6</td>\n",
              "      <td>632070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610114</th>\n",
              "      <td>610114</td>\n",
              "      <td>YYYYHR</td>\n",
              "      <td>3</td>\n",
              "      <td>517</td>\n",
              "      <td>6</td>\n",
              "      <td>632071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610115</th>\n",
              "      <td>610115</td>\n",
              "      <td>YYYYMWK</td>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>7</td>\n",
              "      <td>632072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610116</th>\n",
              "      <td>610116</td>\n",
              "      <td>YYYYWHLR</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>632073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>610117 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2fdf9bd-b55c-4755-b2b5-636824fa8e54')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2fdf9bd-b55c-4755-b2b5-636824fa8e54 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2fdf9bd-b55c-4755-b2b5-636824fa8e54');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-743b684f-7d41-4724-8b3a-8fcb761b7f50\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-743b684f-7d41-4724-8b3a-8fcb761b7f50')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-743b684f-7d41-4724-8b3a-8fcb761b7f50 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7c5208be-e529-4832-a466-1688bde0cbfd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('precursor_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7c5208be-e529-4832-a466-1688bde0cbfd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('precursor_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "precursor_df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Ion Mask**"
      ],
      "metadata": {
        "id": "pxiPRuPuHvX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ion_mask(seq_len, charge, max_seq_len=50):\n",
        "    # a2+ ions\n",
        "    mask = [True]\n",
        "    # b/y ions with charge 1/2/3\n",
        "    for ion in range(1, 3):\n",
        "        for chr in range(1, 4):\n",
        "            if chr > charge:\n",
        "                for seq_idx in range(1, max_seq_len):\n",
        "                    mask.append(False)\n",
        "            else:\n",
        "                for seq_idx in range(1, max_seq_len):\n",
        "                    if seq_idx < seq_len:\n",
        "                        mask.append(True)\n",
        "                    else:\n",
        "                        mask.append(False)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "Zpmu40cYH2Lj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "# Setup Vocabulary and Tokenization\n",
        "#############################################\n",
        "special_tokens = [\"[PAD]\", \"[CLS]\", \"[CHARGE]\", \"[OUTPUT]\"]\n",
        "all_tokens = special_tokens + amino_acids\n",
        "token_to_id = {t: i for i, t in enumerate(all_tokens)}\n",
        "PAD_ID = token_to_id[\"[PAD]\"]\n",
        "CLS_ID = token_to_id[\"[CLS]\"]\n",
        "CHARGE_ID = token_to_id[\"[CHARGE]\"]\n",
        "OUTPUT_ID = token_to_id[\"[OUTPUT]\"]\n",
        "\n",
        "def encode_peptide(seq):\n",
        "    return [token_to_id[aa] for aa in seq if aa in token_to_id]\n",
        "\n",
        "def encode_input(seq, charge, max_length_input):\n",
        "    # Represent charge by repeating the [CHARGE] token 'charge' times\n",
        "    charge_tokens = [CHARGE_ID]*charge\n",
        "    input_ids = [CLS_ID] + encode_peptide(seq) + charge_tokens + [OUTPUT_ID]\n",
        "    # Pad input if necessary\n",
        "    if len(input_ids) > max_length_input:\n",
        "        input_ids = input_ids[:max_length_input]\n",
        "    else:\n",
        "        input_ids += [PAD_ID]*(max_length_input - len(input_ids))\n",
        "    return input_ids"
      ],
      "metadata": {
        "id": "K0a3qzFOH3dD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MS2Dataset(Dataset):\n",
        "    def __init__(self, df, matrix_data, max_length_input=40):\n",
        "        # Precursor, which is a pair of (peptide_sequence, charge)\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.matrix_data = matrix_data\n",
        "        # Maximal length of peptide_sequence + charge state\n",
        "        self.max_length_input = max_length_input\n",
        "        # We need to know output length = num_tokens_to_predict from data\n",
        "        # Assume that we predict all the probabilities for all irons although most of them are zeros\n",
        "        self.output_length = self.matrix_data.shape[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.df.loc[idx, 'sequence']\n",
        "        charge = self.df.loc[idx, 'charge']\n",
        "\n",
        "        input_ids = encode_input(seq, charge, self.max_length_input)\n",
        "        input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
        "\n",
        "        ion_mask = get_ion_mask(len(seq), charge,self.max_length_input)\n",
        "\n",
        "        # matrix_data[idx]: shape [output_length, 4]\n",
        "        # Columns: [m/z, probability, mean_intensity, var_intensity]\n",
        "        # We only predict probability (index 1) right now\n",
        "        row = self.matrix_data[idx]  # shape [output_length, 4]\n",
        "        probability = row[:, 1]  # shape [output_length, 1]\n",
        "\n",
        "        probability = torch.tensor(probability, dtype=torch.float)\n",
        "\n",
        "        # Combined input: input length + output_length\n",
        "        combined_input = torch.cat([input_ids, torch.full((self.output_length,), PAD_ID, dtype=torch.long)])\n",
        "\n",
        "        # Find OUTPUT token and get its position\n",
        "        output_pos_tensor = (combined_input == OUTPUT_ID).nonzero(as_tuple=True)[0]\n",
        "        output_pos = output_pos_tensor.item() if output_pos_tensor.numel() > 0 else -1  # Assign -1 if not found\n",
        "\n",
        "        return combined_input, probability, output_pos, torch.BoolTensor(ion_mask)"
      ],
      "metadata": {
        "id": "u4spkVYBH9XL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformer Model**"
      ],
      "metadata": {
        "id": "EDq-lTWJICFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "# Model Decoder-only Transformer\n",
        "#############################################\n",
        "class DecoderOnlyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, nhead=4, num_layers=4, dim_feedforward=512, max_len=300, pad_id=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len, d_model))\n",
        "\n",
        "        layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,dropout=0.2)\n",
        "        self.decoder = nn.TransformerDecoder(layer, num_layers=num_layers)\n",
        "\n",
        "        # Output head: probability\n",
        "        self.output_head = nn.Linear(d_model, 1)\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        B, L = input_ids.size()\n",
        "        x = self.embedding(input_ids) + self.pos_embedding[:, :L, :]  # [B, L, D]\n",
        "\n",
        "        tgt_mask = self._generate_square_subsequent_mask(L).to(input_ids.device)\n",
        "\n",
        "        x = x.permute(1, 0, 2)\n",
        "        out = self.decoder(tgt=x, memory=x, tgt_mask=tgt_mask)\n",
        "        out = out.permute(1, 0, 2)  # [B, L, D]\n",
        "\n",
        "        preds = self.output_head(out)  # [B, L, 2]\n",
        "        return preds\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = torch.full((sz, sz), float('-inf'))\n",
        "        mask = torch.triu(mask, diagonal=1)\n",
        "        return mask"
      ],
      "metadata": {
        "id": "mOHspX2KILB7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train/test split**"
      ],
      "metadata": {
        "id": "qBKoFf1cISbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "#  Train/test Data\n",
        "#############################################\n",
        "N = len(precursor_df)\n",
        "print(\"Total number of precursors:\", N)\n",
        "train_indices = train_test_split_set['train_indices']\n",
        "test_indices = train_test_split_set['test_indices']\n",
        "\n",
        "train_df = precursor_df.iloc[train_indices].reset_index(drop=True)\n",
        "test_df = precursor_df.iloc[test_indices].reset_index(drop=True)\n",
        "train_matrix = matrix[train_indices]\n",
        "test_matrix = matrix[test_indices]\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Test size:\", len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pksdDzWXIOip",
        "outputId": "adf1fb0d-b427-456d-dfa4-f52c630abc23"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of precursors: 610117\n",
            "Train size: 497197\n",
            "Test size: 132260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_input = 40\n",
        "batch_size = 512\n",
        "\n",
        "#############################################\n",
        "# Create training and test Dataset Loaders\n",
        "#############################################\n",
        "\n",
        "train_dataset = MS2Dataset(train_df, train_matrix, max_length_input=max_length_input)\n",
        "test_dataset = MS2Dataset(test_df, test_matrix, max_length_input=max_length_input)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = batch_size,     # you may want to scale this up (e.g. 4×) now that you have 4 GPUs\n",
        "    shuffle    = True,\n",
        "    num_workers= 4,\n",
        "    pin_memory = True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle    = False,\n",
        "    num_workers= 0,\n",
        "    pin_memory = False\n",
        ")\n",
        "\n",
        "output_length = train_dataset.output_length\n",
        "max_len = max_length_input + output_length"
      ],
      "metadata": {
        "id": "mh6KMpBuIc20"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up transformer model**"
      ],
      "metadata": {
        "id": "FNV9hcCxIr5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 180\n",
        "lr = 0.001\n",
        "epochs = 5\n",
        "\n",
        "model = DecoderOnlyTransformer(vocab_size=len(all_tokens), d_model=d_model, max_len=max_len)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    model = nn.DataParallel(model)\n",
        "model = model.to(device)\n",
        "criterion = nn.L1Loss(reduction='none')\n",
        "MSE_loss = torch.nn.MSELoss(reduction='none')\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',       # we want val loss to go down\n",
        "    factor=0.5,       # cut LR in half on plateau\n",
        "    patience=5,       # wait 5 epochs with no improvement\n",
        "    min_lr=1e-6       # never go below this LR\n",
        ")\n",
        "\n",
        "# metric histories\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "mse_list = []\n",
        "\n",
        "print(\"Total number of parameters:\",sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol_EHtuxIqoR",
        "outputId": "75f3d337-443c-4221-fd42-d7927dc2df37"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 1840749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and Evaluation loops**"
      ],
      "metadata": {
        "id": "UdzsVPNTJK-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "# Training & Evaluation Loop\n",
        "#############################################\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    # Training\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_batch, target_batch, output_pos_batch, ion_mask_batch = batch\n",
        "        input_batch = input_batch.to(device, non_blocking=True)\n",
        "        target_batch = target_batch.to(device, non_blocking=True)\n",
        "        output_pos_batch = output_pos_batch.to(device, non_blocking=True)\n",
        "\n",
        "        preds = model(input_batch)  # [B, L, 1]\n",
        "\n",
        "        B, L, _ = preds.size()\n",
        "        # Create mask for output positions\n",
        "        mask = torch.zeros(B, L, dtype=torch.bool, device=preds.device)\n",
        "        for i in range(B):\n",
        "            start_idx = output_pos_batch[i].item() + 1\n",
        "            end_idx = start_idx + output_length\n",
        "            mask[i, start_idx:end_idx] = True\n",
        "\n",
        "        preds_output = torch.sigmoid(preds[mask].view(B, output_length,1))\n",
        "        ion_mask_batch = ion_mask_batch.float().view(B, output_length,1).to(device)\n",
        "        per_token_loss = criterion(preds_output, target_batch.view(B, output_length, 1))\n",
        "        masked_loss  = per_token_loss * ion_mask_batch\n",
        "        loss_sum_per_sample = masked_loss.sum(dim=(1,2))\n",
        "        n_valid_per_sample = ion_mask_batch.sum(dim=(1,2))\n",
        "        per_sample_loss = loss_sum_per_sample / (n_valid_per_sample + 1e-8)\n",
        "        loss = per_sample_loss.mean()\n",
        "        # loss = loss.mean()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    running_test_loss = 0.0\n",
        "    mse_total        = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, target, out_pos, ion_mask in test_loader:\n",
        "            # Move everything once\n",
        "            input_ids = input_ids.to(device, non_blocking=True)\n",
        "            target    = target.to(device,    non_blocking=True)\n",
        "            out_pos   = out_pos.to(device,   non_blocking=True)\n",
        "            # shape: [B, output_length]\n",
        "            ion_mask = ion_mask.to(device).float().unsqueeze(-1)  # [B, O, 1]\n",
        "\n",
        "            # 1) Forward + sigmoid\n",
        "            logits = model(input_ids)                # [B, L, 1]\n",
        "            probs  = torch.sigmoid(logits)           # [B, L, 1]\n",
        "            B, L, _ = probs.shape\n",
        "\n",
        "            # 2) Build a [B, L] boolean mask of “where we predict ions”\n",
        "            positions = torch.arange(L, device=device).unsqueeze(0)     # [1, L]\n",
        "            start     = (out_pos + 1).unsqueeze(1)                      # [B, 1]\n",
        "            valid_pos = (positions >= start) & (positions < start + output_length)  # [B, L]\n",
        "            valid_pos = valid_pos.unsqueeze(-1)                        # [B, L, 1]\n",
        "\n",
        "            # 3) Slice out exactly the O prediction spots\n",
        "            preds_out = probs[valid_pos].view(B, output_length, 1)     # [B, O, 1]\n",
        "            targ_out  = target.view(B, output_length, 1)\n",
        "\n",
        "            # 4) Per-token absolute and squared errors\n",
        "            abs_err = (preds_out - targ_out).abs()                     # [B, O, 1]\n",
        "            sq_err  = (preds_out - targ_out).pow(2)                    # [B, O, 1]\n",
        "\n",
        "            # 5) Apply your ion mask\n",
        "            abs_err = abs_err * ion_mask\n",
        "            sq_err  = sq_err  * ion_mask\n",
        "\n",
        "            # 6) Sum over tokens → one loss per sample\n",
        "            sum_abs = abs_err.sum(dim=(1,2))                           # [B]\n",
        "            sum_sq  = sq_err.sum(dim=(1,2))                            # [B]\n",
        "            cnt     = ion_mask.sum(dim=(1,2)).clamp(min=1e-8)          # [B]\n",
        "\n",
        "            loss_per_sample = sum_abs / cnt                            # [B]\n",
        "            mse_per_sample  = sum_sq  / cnt                            # [B]\n",
        "\n",
        "            # 7) Average over the batch\n",
        "            running_test_loss += loss_per_sample.mean().item()\n",
        "            mse_total        += mse_per_sample.mean().item()\n",
        "\n",
        "    # Final averages\n",
        "    avg_test_loss = running_test_loss / len(test_loader)\n",
        "    avg_mse       = mse_total        / len(test_loader)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    mse_list.append(avg_mse)\n",
        "    # Print results\n",
        "    print(f\"Training MAE: {avg_train_loss:.4f}, Test MAE: {avg_test_loss:.4f}, MSE: {avg_mse:.4f}\")\n",
        "    # 1) Step the ReduceLROnPlateau scheduler\n",
        "    scheduler.step(avg_test_loss)\n",
        "\n",
        "    # 2) (Optional) log the updated LR\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Epoch {epoch+1}: val_loss={avg_test_loss:.4f}, lr={current_lr:.2e}\")\n",
        "    if (epoch + 1) % 4 == 0:\n",
        "        torch.save(\n",
        "            model.state_dict(),\n",
        "            f\"checheckpoint_path0_epoch{epoch+1:02d}.pth\"\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJKCCapaI_uU",
        "outputId": "8e218426-f607-4d57-bd66-57404953194b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "  0%|          | 0/972 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/972 [00:01<24:44,  1.53s/it]\u001b[A\n",
            "  0%|          | 2/972 [00:01<13:54,  1.16it/s]\u001b[A\n",
            "  0%|          | 3/972 [00:02<10:26,  1.55it/s]\u001b[A\n",
            "  0%|          | 4/972 [00:02<08:48,  1.83it/s]\u001b[A\n",
            "  1%|          | 5/972 [00:03<07:53,  2.04it/s]\u001b[A\n",
            "  1%|          | 6/972 [00:03<07:20,  2.19it/s]\u001b[A\n",
            "  1%|          | 7/972 [00:03<06:59,  2.30it/s]\u001b[A\n",
            "  1%|          | 8/972 [00:04<06:45,  2.38it/s]\u001b[A\n",
            "  1%|          | 9/972 [00:04<06:36,  2.43it/s]\u001b[A\n",
            "  1%|          | 10/972 [00:05<06:29,  2.47it/s]\u001b[A\n",
            "  1%|          | 11/972 [00:05<06:25,  2.50it/s]\u001b[A\n",
            "  1%|          | 12/972 [00:05<06:21,  2.51it/s]\u001b[A\n",
            "  1%|▏         | 13/972 [00:06<06:19,  2.53it/s]\u001b[A\n",
            "  1%|▏         | 14/972 [00:06<06:17,  2.54it/s]\u001b[A\n",
            "  2%|▏         | 15/972 [00:07<06:18,  2.53it/s]\u001b[A\n",
            "  2%|▏         | 16/972 [00:07<06:16,  2.54it/s]\u001b[A\n",
            "  2%|▏         | 17/972 [00:07<06:15,  2.54it/s]\u001b[A\n",
            "  2%|▏         | 18/972 [00:08<06:14,  2.55it/s]\u001b[A\n",
            "  2%|▏         | 19/972 [00:08<06:13,  2.55it/s]\u001b[A\n",
            "  2%|▏         | 20/972 [00:08<06:12,  2.55it/s]\u001b[A\n",
            "  2%|▏         | 21/972 [00:09<06:11,  2.56it/s]\u001b[A\n",
            "  2%|▏         | 22/972 [00:09<06:11,  2.56it/s]\u001b[A\n",
            "  2%|▏         | 23/972 [00:10<06:11,  2.56it/s]\u001b[A\n",
            "  2%|▏         | 24/972 [00:10<06:10,  2.56it/s]\u001b[A\n",
            "  3%|▎         | 25/972 [00:10<06:10,  2.55it/s]\u001b[A\n",
            "  3%|▎         | 26/972 [00:11<06:12,  2.54it/s]\u001b[A\n",
            "  3%|▎         | 27/972 [00:11<06:10,  2.55it/s]\u001b[A\n",
            "  3%|▎         | 28/972 [00:12<06:09,  2.55it/s]\u001b[A\n",
            "  3%|▎         | 29/972 [00:12<06:09,  2.55it/s]\u001b[A\n",
            "  3%|▎         | 30/972 [00:12<06:09,  2.55it/s]\u001b[A\n",
            "  3%|▎         | 31/972 [00:13<06:08,  2.55it/s]\u001b[A\n",
            "  3%|▎         | 32/972 [00:13<06:07,  2.56it/s]\u001b[A\n",
            "  3%|▎         | 33/972 [00:14<06:07,  2.56it/s]\u001b[A\n",
            "  3%|▎         | 34/972 [00:14<06:06,  2.56it/s]\u001b[A\n",
            "  4%|▎         | 35/972 [00:14<06:06,  2.56it/s]\u001b[A\n",
            "  4%|▎         | 36/972 [00:15<06:06,  2.56it/s]\u001b[A\n",
            "  4%|▍         | 37/972 [00:15<06:05,  2.56it/s]\u001b[A\n",
            "  4%|▍         | 38/972 [00:16<06:04,  2.56it/s]\u001b[A\n",
            "  4%|▍         | 39/972 [00:16<06:04,  2.56it/s]\u001b[A\n",
            "  4%|▍         | 40/972 [00:16<06:03,  2.56it/s]\u001b[A\n",
            "  4%|▍         | 41/972 [00:17<06:03,  2.56it/s]\u001b[A\n",
            "  4%|▍         | 42/972 [00:17<06:03,  2.56it/s]\u001b[A\n",
            "  4%|▍         | 43/972 [00:17<06:02,  2.56it/s]\u001b[A\n",
            "  5%|▍         | 44/972 [00:18<06:02,  2.56it/s]\u001b[A\n",
            "  5%|▍         | 45/972 [00:18<06:01,  2.56it/s]\u001b[A\n",
            "  5%|▍         | 46/972 [00:19<06:01,  2.56it/s]\u001b[A\n",
            "  5%|▍         | 47/972 [00:19<06:01,  2.56it/s]\u001b[A\n",
            "  5%|▍         | 48/972 [00:19<06:00,  2.56it/s]\u001b[A\n",
            "  5%|▌         | 49/972 [00:20<06:00,  2.56it/s]\u001b[A\n",
            "  5%|▌         | 50/972 [00:20<06:00,  2.56it/s]\u001b[A\n",
            "  5%|▌         | 51/972 [00:21<05:59,  2.56it/s]\u001b[A\n",
            "  5%|▌         | 52/972 [00:21<05:59,  2.56it/s]\u001b[A\n",
            "  5%|▌         | 53/972 [00:21<05:58,  2.56it/s]\u001b[A\n",
            "  6%|▌         | 54/972 [00:22<05:58,  2.56it/s]\u001b[A\n",
            "  6%|▌         | 55/972 [00:22<05:58,  2.56it/s]\u001b[A\n",
            "  6%|▌         | 56/972 [00:23<05:57,  2.56it/s]\u001b[A\n",
            "  6%|▌         | 57/972 [00:23<05:57,  2.56it/s]\u001b[A\n",
            "  6%|▌         | 58/972 [00:23<05:57,  2.56it/s]\u001b[A\n",
            "  6%|▌         | 59/972 [00:24<05:57,  2.56it/s]\u001b[A\n",
            "  6%|▌         | 60/972 [00:24<05:56,  2.56it/s]\u001b[A\n",
            "  6%|▋         | 61/972 [00:24<05:56,  2.56it/s]\u001b[A\n",
            "  6%|▋         | 62/972 [00:25<05:56,  2.55it/s]\u001b[A\n",
            "  6%|▋         | 63/972 [00:25<05:55,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 64/972 [00:26<05:55,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 65/972 [00:26<05:54,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 66/972 [00:26<05:54,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 67/972 [00:27<05:53,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 68/972 [00:27<05:53,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 69/972 [00:28<05:52,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 70/972 [00:28<05:52,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 71/972 [00:28<05:51,  2.56it/s]\u001b[A\n",
            "  7%|▋         | 72/972 [00:29<05:51,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 73/972 [00:29<05:50,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 74/972 [00:30<05:50,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 75/972 [00:30<05:49,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 76/972 [00:30<05:49,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 77/972 [00:31<05:49,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 78/972 [00:31<05:48,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 79/972 [00:32<05:48,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 80/972 [00:32<05:49,  2.55it/s]\u001b[A\n",
            "  8%|▊         | 81/972 [00:32<05:48,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 82/972 [00:33<05:47,  2.56it/s]\u001b[A\n",
            "  9%|▊         | 83/972 [00:33<05:47,  2.56it/s]\u001b[A\n",
            "  9%|▊         | 84/972 [00:33<05:46,  2.56it/s]\u001b[A\n",
            "  9%|▊         | 85/972 [00:34<05:46,  2.56it/s]\u001b[A\n",
            "  9%|▉         | 86/972 [00:34<05:45,  2.56it/s]\u001b[A\n",
            "  9%|▉         | 87/972 [00:35<05:45,  2.56it/s]\u001b[A\n",
            "  9%|▉         | 88/972 [00:35<05:45,  2.56it/s]\u001b[A\n",
            "  9%|▉         | 89/972 [00:35<05:45,  2.56it/s]\u001b[A\n",
            "  9%|▉         | 90/972 [00:36<05:46,  2.54it/s]\u001b[A\n",
            "  9%|▉         | 91/972 [00:36<05:45,  2.55it/s]\u001b[A\n",
            "  9%|▉         | 92/972 [00:37<05:44,  2.55it/s]\u001b[A\n",
            " 10%|▉         | 93/972 [00:37<05:44,  2.55it/s]\u001b[A\n",
            " 10%|▉         | 94/972 [00:37<05:43,  2.56it/s]\u001b[A\n",
            " 10%|▉         | 95/972 [00:38<05:44,  2.55it/s]\u001b[A\n",
            " 10%|▉         | 96/972 [00:38<05:43,  2.55it/s]\u001b[A\n",
            " 10%|▉         | 97/972 [00:39<05:42,  2.56it/s]\u001b[A\n",
            " 10%|█         | 98/972 [00:39<05:41,  2.56it/s]\u001b[A\n",
            " 10%|█         | 99/972 [00:39<05:40,  2.56it/s]\u001b[A\n",
            " 10%|█         | 100/972 [00:40<05:40,  2.56it/s]\u001b[A\n",
            " 10%|█         | 101/972 [00:40<05:40,  2.56it/s]\u001b[A\n",
            " 10%|█         | 102/972 [00:41<05:39,  2.56it/s]\u001b[A\n",
            " 11%|█         | 103/972 [00:41<05:39,  2.56it/s]\u001b[A\n",
            " 11%|█         | 104/972 [00:41<05:38,  2.56it/s]\u001b[A\n",
            " 11%|█         | 105/972 [00:42<05:38,  2.56it/s]\u001b[A\n",
            " 11%|█         | 106/972 [00:42<05:38,  2.56it/s]\u001b[A\n",
            " 11%|█         | 107/972 [00:42<05:37,  2.56it/s]\u001b[A\n",
            " 11%|█         | 108/972 [00:43<05:37,  2.56it/s]\u001b[A\n",
            " 11%|█         | 109/972 [00:43<05:36,  2.56it/s]\u001b[A\n",
            " 11%|█▏        | 110/972 [00:44<05:36,  2.56it/s]\u001b[A\n",
            " 11%|█▏        | 111/972 [00:44<05:36,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 112/972 [00:44<05:35,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 113/972 [00:45<05:35,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 114/972 [00:45<05:34,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 115/972 [00:46<05:34,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 116/972 [00:46<05:34,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 117/972 [00:46<05:33,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 118/972 [00:47<05:33,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 119/972 [00:47<05:33,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 120/972 [00:48<05:32,  2.56it/s]\u001b[A\n",
            " 12%|█▏        | 121/972 [00:48<05:32,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 122/972 [00:48<05:31,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 123/972 [00:49<05:31,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 124/972 [00:49<05:31,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 125/972 [00:49<05:30,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 126/972 [00:50<05:30,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 127/972 [00:50<05:29,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 128/972 [00:51<05:29,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 129/972 [00:51<05:29,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 130/972 [00:51<05:28,  2.56it/s]\u001b[A\n",
            " 13%|█▎        | 131/972 [00:52<05:28,  2.56it/s]\u001b[A\n",
            " 14%|█▎        | 132/972 [00:52<05:28,  2.56it/s]\u001b[A\n",
            " 14%|█▎        | 133/972 [00:53<05:27,  2.56it/s]\u001b[A\n",
            " 14%|█▍        | 134/972 [00:53<05:27,  2.56it/s]\u001b[A\n",
            " 14%|█▍        | 135/972 [00:53<05:26,  2.56it/s]\u001b[A\n",
            " 14%|█▍        | 136/972 [00:54<05:26,  2.56it/s]\u001b[A\n",
            " 14%|█▍        | 137/972 [00:54<05:26,  2.56it/s]\u001b[A\n",
            " 14%|█▍        | 138/972 [00:55<05:25,  2.56it/s]\u001b[A\n",
            " 14%|█▍        | 139/972 [00:55<05:25,  2.56it/s]\u001b[A\n",
            " 14%|█▍        | 140/972 [00:55<05:24,  2.56it/s]\u001b[A\n",
            " 15%|█▍        | 141/972 [00:56<05:24,  2.56it/s]\u001b[A\n",
            " 15%|█▍        | 142/972 [00:56<05:24,  2.56it/s]\u001b[A\n",
            " 15%|█▍        | 143/972 [00:57<05:23,  2.56it/s]\u001b[A\n",
            " 15%|█▍        | 144/972 [00:57<05:23,  2.56it/s]\u001b[A\n",
            " 15%|█▍        | 145/972 [00:57<05:22,  2.56it/s]\u001b[A\n",
            " 15%|█▌        | 146/972 [00:58<05:22,  2.56it/s]\u001b[A\n",
            " 15%|█▌        | 147/972 [00:58<05:22,  2.56it/s]\u001b[A\n",
            " 15%|█▌        | 148/972 [00:58<05:21,  2.56it/s]\u001b[A\n",
            " 15%|█▌        | 149/972 [00:59<05:21,  2.56it/s]\u001b[A\n",
            " 15%|█▌        | 150/972 [00:59<05:21,  2.56it/s]\u001b[A\n",
            " 16%|█▌        | 151/972 [01:00<05:22,  2.54it/s]\u001b[A\n",
            " 16%|█▌        | 152/972 [01:00<05:21,  2.55it/s]\u001b[A\n",
            " 16%|█▌        | 153/972 [01:00<05:20,  2.55it/s]\u001b[A\n",
            " 16%|█▌        | 154/972 [01:01<05:20,  2.56it/s]\u001b[A\n",
            " 16%|█▌        | 155/972 [01:01<05:19,  2.56it/s]\u001b[A\n",
            " 16%|█▌        | 156/972 [01:02<05:20,  2.55it/s]\u001b[A\n",
            " 16%|█▌        | 157/972 [01:02<05:19,  2.55it/s]\u001b[A\n",
            " 16%|█▋        | 158/972 [01:02<05:18,  2.56it/s]\u001b[A\n",
            " 16%|█▋        | 159/972 [01:03<05:17,  2.56it/s]\u001b[A\n",
            " 16%|█▋        | 160/972 [01:03<05:17,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 161/972 [01:04<05:16,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 162/972 [01:04<05:16,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 163/972 [01:04<05:15,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 164/972 [01:05<05:15,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 165/972 [01:05<05:14,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 166/972 [01:06<05:14,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 167/972 [01:06<05:14,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 168/972 [01:06<05:13,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 169/972 [01:07<05:13,  2.56it/s]\u001b[A\n",
            " 17%|█▋        | 170/972 [01:07<05:13,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 171/972 [01:07<05:12,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 172/972 [01:08<05:12,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 173/972 [01:08<05:12,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 174/972 [01:09<05:11,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 175/972 [01:09<05:11,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 176/972 [01:09<05:10,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 177/972 [01:10<05:10,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 178/972 [01:10<05:10,  2.56it/s]\u001b[A\n",
            " 18%|█▊        | 179/972 [01:11<05:09,  2.56it/s]\u001b[A\n",
            " 19%|█▊        | 180/972 [01:11<05:09,  2.56it/s]\u001b[A\n",
            " 19%|█▊        | 181/972 [01:11<05:09,  2.56it/s]\u001b[A\n",
            " 19%|█▊        | 182/972 [01:12<05:08,  2.56it/s]\u001b[A\n",
            " 19%|█▉        | 183/972 [01:12<05:08,  2.56it/s]\u001b[A\n",
            " 19%|█▉        | 184/972 [01:13<05:08,  2.56it/s]\u001b[A\n",
            " 19%|█▉        | 185/972 [01:13<05:07,  2.56it/s]\u001b[A\n",
            " 19%|█▉        | 186/972 [01:13<05:07,  2.56it/s]\u001b[A\n",
            " 19%|█▉        | 187/972 [01:14<05:06,  2.56it/s]\u001b[A\n",
            " 19%|█▉        | 188/972 [01:14<05:06,  2.56it/s]\u001b[A\n",
            " 19%|█▉        | 189/972 [01:15<05:05,  2.56it/s]\u001b[A\n",
            " 20%|█▉        | 190/972 [01:15<05:05,  2.56it/s]\u001b[A\n",
            " 20%|█▉        | 191/972 [01:15<05:05,  2.56it/s]\u001b[A\n",
            " 20%|█▉        | 192/972 [01:16<05:04,  2.56it/s]\u001b[A\n",
            " 20%|█▉        | 193/972 [01:16<05:04,  2.56it/s]\u001b[A\n",
            " 20%|█▉        | 194/972 [01:16<05:03,  2.56it/s]\u001b[A\n",
            " 20%|██        | 195/972 [01:17<05:03,  2.56it/s]\u001b[A\n",
            " 20%|██        | 196/972 [01:17<05:02,  2.56it/s]\u001b[A\n",
            " 20%|██        | 197/972 [01:18<05:02,  2.56it/s]\u001b[A\n",
            " 20%|██        | 198/972 [01:18<05:02,  2.56it/s]\u001b[A\n",
            " 20%|██        | 199/972 [01:18<05:01,  2.56it/s]\u001b[A\n",
            " 21%|██        | 200/972 [01:19<05:01,  2.56it/s]\u001b[A\n",
            " 21%|██        | 201/972 [01:19<05:01,  2.56it/s]\u001b[A\n",
            " 21%|██        | 202/972 [01:20<05:00,  2.56it/s]\u001b[A\n",
            " 21%|██        | 203/972 [01:20<05:00,  2.56it/s]\u001b[A\n",
            " 21%|██        | 204/972 [01:20<04:59,  2.56it/s]\u001b[A\n",
            " 21%|██        | 205/972 [01:21<04:59,  2.56it/s]\u001b[A\n",
            " 21%|██        | 206/972 [01:21<04:59,  2.56it/s]\u001b[A\n",
            " 21%|██▏       | 207/972 [01:22<04:58,  2.56it/s]\u001b[A\n",
            " 21%|██▏       | 208/972 [01:22<04:58,  2.56it/s]\u001b[A\n",
            " 22%|██▏       | 209/972 [01:22<04:57,  2.56it/s]\u001b[A\n",
            " 22%|██▏       | 210/972 [01:23<04:57,  2.56it/s]\u001b[A\n",
            " 22%|██▏       | 211/972 [01:23<04:57,  2.56it/s]\u001b[A\n",
            " 22%|██▏       | 212/972 [01:23<04:56,  2.56it/s]\u001b[A\n",
            " 22%|██▏       | 213/972 [01:24<04:56,  2.56it/s]\u001b[A\n",
            " 22%|██▏       | 214/972 [01:24<04:56,  2.56it/s]\u001b[A\n",
            " 22%|██▏       | 215/972 [01:25<04:57,  2.55it/s]\u001b[A\n",
            " 22%|██▏       | 216/972 [01:25<04:56,  2.55it/s]\u001b[A\n",
            " 22%|██▏       | 217/972 [01:25<04:55,  2.55it/s]\u001b[A\n",
            " 22%|██▏       | 218/972 [01:26<04:54,  2.56it/s]\u001b[A\n",
            " 23%|██▎       | 219/972 [01:26<04:54,  2.56it/s]\u001b[A\n",
            " 23%|██▎       | 220/972 [01:27<04:55,  2.55it/s]\u001b[A\n",
            " 23%|██▎       | 221/972 [01:27<04:54,  2.55it/s]\u001b[A\n",
            " 23%|██▎       | 222/972 [01:27<04:53,  2.55it/s]\u001b[A\n",
            " 23%|██▎       | 223/972 [01:28<04:53,  2.55it/s]\u001b[A\n",
            " 23%|██▎       | 224/972 [01:28<04:52,  2.56it/s]\u001b[A\n",
            " 23%|██▎       | 225/972 [01:29<04:52,  2.55it/s]\u001b[A\n",
            " 23%|██▎       | 226/972 [01:29<04:52,  2.55it/s]\u001b[A\n",
            " 23%|██▎       | 227/972 [01:29<04:51,  2.56it/s]\u001b[A\n",
            " 23%|██▎       | 228/972 [01:30<04:52,  2.55it/s]\u001b[A\n",
            " 24%|██▎       | 229/972 [01:30<04:51,  2.55it/s]\u001b[A\n",
            " 24%|██▎       | 230/972 [01:31<04:50,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 231/972 [01:31<04:49,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 232/972 [01:31<04:50,  2.55it/s]\u001b[A\n",
            " 24%|██▍       | 233/972 [01:32<04:49,  2.55it/s]\u001b[A\n",
            " 24%|██▍       | 234/972 [01:32<04:48,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 235/972 [01:32<04:48,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 236/972 [01:33<04:47,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 237/972 [01:33<04:47,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 238/972 [01:34<04:48,  2.54it/s]\u001b[A\n",
            " 25%|██▍       | 239/972 [01:34<04:47,  2.55it/s]\u001b[A\n",
            " 25%|██▍       | 240/972 [01:34<04:46,  2.55it/s]\u001b[A\n",
            " 25%|██▍       | 241/972 [01:35<04:46,  2.55it/s]\u001b[A\n",
            " 25%|██▍       | 242/972 [01:35<04:45,  2.56it/s]\u001b[A\n",
            " 25%|██▌       | 243/972 [01:36<04:46,  2.55it/s]\u001b[A\n",
            " 25%|██▌       | 244/972 [01:36<04:45,  2.55it/s]\u001b[A\n",
            " 25%|██▌       | 245/972 [01:36<04:44,  2.55it/s]\u001b[A\n",
            " 25%|██▌       | 246/972 [01:37<04:44,  2.56it/s]\u001b[A\n",
            " 25%|██▌       | 247/972 [01:37<04:43,  2.55it/s]\u001b[A\n",
            " 26%|██▌       | 248/972 [01:38<04:43,  2.56it/s]\u001b[A\n",
            " 26%|██▌       | 249/972 [01:38<04:42,  2.56it/s]\u001b[A\n",
            " 26%|██▌       | 250/972 [01:38<04:42,  2.56it/s]\u001b[A\n",
            " 26%|██▌       | 251/972 [01:39<04:41,  2.56it/s]\u001b[A\n",
            " 26%|██▌       | 252/972 [01:39<04:41,  2.56it/s]\u001b[A\n",
            " 26%|██▌       | 253/972 [01:40<04:40,  2.56it/s]\u001b[A\n",
            " 26%|██▌       | 254/972 [01:40<04:40,  2.56it/s]\u001b[A\n",
            " 26%|██▌       | 255/972 [01:40<04:40,  2.56it/s]\u001b[A\n",
            " 26%|██▋       | 256/972 [01:41<04:39,  2.56it/s]\u001b[A\n",
            " 26%|██▋       | 257/972 [01:41<04:39,  2.56it/s]\u001b[A\n",
            " 27%|██▋       | 258/972 [01:41<04:38,  2.56it/s]\u001b[A\n",
            " 27%|██▋       | 259/972 [01:42<04:38,  2.56it/s]\u001b[A\n",
            " 27%|██▋       | 260/972 [01:42<04:38,  2.56it/s]\u001b[A\n",
            " 27%|██▋       | 261/972 [01:43<04:37,  2.56it/s]\u001b[A\n",
            " 27%|██▋       | 262/972 [01:43<04:37,  2.56it/s]\u001b[A\n",
            " 27%|██▋       | 263/972 [01:43<04:37,  2.55it/s]\u001b[A\n",
            " 27%|██▋       | 264/972 [01:44<04:37,  2.55it/s]\u001b[A\n",
            " 27%|██▋       | 265/972 [01:44<04:36,  2.56it/s]\u001b[A\n",
            " 27%|██▋       | 266/972 [01:45<04:35,  2.56it/s]\u001b[A\n",
            " 27%|██▋       | 267/972 [01:45<04:35,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 268/972 [01:45<04:34,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 269/972 [01:46<04:34,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 270/972 [01:46<04:34,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 271/972 [01:47<04:34,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 272/972 [01:47<04:33,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 273/972 [01:47<04:33,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 274/972 [01:48<04:32,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 275/972 [01:48<04:32,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 276/972 [01:49<04:31,  2.56it/s]\u001b[A\n",
            " 28%|██▊       | 277/972 [01:49<04:31,  2.56it/s]\u001b[A\n",
            " 29%|██▊       | 278/972 [01:49<04:31,  2.56it/s]\u001b[A\n",
            " 29%|██▊       | 279/972 [01:50<04:30,  2.56it/s]\u001b[A\n",
            " 29%|██▉       | 280/972 [01:50<04:30,  2.56it/s]\u001b[A\n",
            " 29%|██▉       | 281/972 [01:50<04:29,  2.56it/s]\u001b[A\n",
            " 29%|██▉       | 282/972 [01:51<04:29,  2.56it/s]\u001b[A\n",
            " 29%|██▉       | 283/972 [01:51<04:28,  2.56it/s]\u001b[A\n",
            " 29%|██▉       | 284/972 [01:52<04:30,  2.55it/s]\u001b[A\n",
            " 29%|██▉       | 285/972 [01:52<04:29,  2.55it/s]\u001b[A\n",
            " 29%|██▉       | 286/972 [01:52<04:28,  2.56it/s]\u001b[A\n",
            " 30%|██▉       | 287/972 [01:53<04:27,  2.56it/s]\u001b[A\n",
            " 30%|██▉       | 288/972 [01:53<04:27,  2.56it/s]\u001b[A\n",
            " 30%|██▉       | 289/972 [01:54<04:26,  2.56it/s]\u001b[A\n",
            " 30%|██▉       | 290/972 [01:54<04:26,  2.56it/s]\u001b[A\n",
            " 30%|██▉       | 291/972 [01:54<04:25,  2.56it/s]\u001b[A\n",
            " 30%|███       | 292/972 [01:55<04:25,  2.56it/s]\u001b[A\n",
            " 30%|███       | 293/972 [01:55<04:25,  2.56it/s]\u001b[A\n",
            " 30%|███       | 294/972 [01:56<04:24,  2.56it/s]\u001b[A\n",
            " 30%|███       | 295/972 [01:56<04:24,  2.56it/s]\u001b[A\n",
            " 30%|███       | 296/972 [01:56<04:24,  2.56it/s]\u001b[A\n",
            " 31%|███       | 297/972 [01:57<04:23,  2.56it/s]\u001b[A\n",
            " 31%|███       | 298/972 [01:57<04:23,  2.56it/s]\u001b[A\n",
            " 31%|███       | 299/972 [01:58<04:23,  2.56it/s]\u001b[A\n",
            " 31%|███       | 300/972 [01:58<04:22,  2.56it/s]\u001b[A\n",
            " 31%|███       | 301/972 [01:58<04:22,  2.56it/s]\u001b[A\n",
            " 31%|███       | 302/972 [01:59<04:21,  2.56it/s]\u001b[A\n",
            " 31%|███       | 303/972 [01:59<04:21,  2.56it/s]\u001b[A\n",
            " 31%|███▏      | 304/972 [01:59<04:20,  2.56it/s]\u001b[A\n",
            " 31%|███▏      | 305/972 [02:00<04:20,  2.56it/s]\u001b[A\n",
            " 31%|███▏      | 306/972 [02:00<04:20,  2.56it/s]\u001b[A\n",
            " 32%|███▏      | 307/972 [02:01<04:19,  2.56it/s]\u001b[A\n",
            " 32%|███▏      | 308/972 [02:01<04:20,  2.55it/s]\u001b[A\n",
            " 32%|███▏      | 309/972 [02:01<04:19,  2.55it/s]\u001b[A\n",
            " 32%|███▏      | 310/972 [02:02<04:19,  2.55it/s]\u001b[A\n",
            " 32%|███▏      | 311/972 [02:02<04:18,  2.56it/s]\u001b[A\n",
            " 32%|███▏      | 312/972 [02:03<04:19,  2.54it/s]\u001b[A\n",
            " 32%|███▏      | 313/972 [02:03<04:18,  2.55it/s]\u001b[A\n",
            " 32%|███▏      | 314/972 [02:03<04:17,  2.55it/s]\u001b[A\n",
            " 32%|███▏      | 315/972 [02:04<04:17,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 316/972 [02:04<04:16,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 317/972 [02:05<04:15,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 318/972 [02:05<04:16,  2.55it/s]\u001b[A\n",
            " 33%|███▎      | 319/972 [02:05<04:15,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 320/972 [02:06<04:14,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 321/972 [02:06<04:14,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 322/972 [02:07<04:13,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 323/972 [02:07<04:13,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 324/972 [02:07<04:12,  2.56it/s]\u001b[A\n",
            " 33%|███▎      | 325/972 [02:08<04:14,  2.55it/s]\u001b[A\n",
            " 34%|███▎      | 326/972 [02:08<04:13,  2.55it/s]\u001b[A\n",
            " 34%|███▎      | 327/972 [02:08<04:12,  2.55it/s]\u001b[A\n",
            " 34%|███▎      | 328/972 [02:09<04:11,  2.56it/s]\u001b[A\n",
            " 34%|███▍      | 329/972 [02:09<04:11,  2.56it/s]\u001b[A\n",
            " 34%|███▍      | 330/972 [02:10<04:10,  2.56it/s]\u001b[A\n",
            " 34%|███▍      | 331/972 [02:10<04:11,  2.55it/s]\u001b[A\n",
            " 34%|███▍      | 332/972 [02:10<04:10,  2.55it/s]\u001b[A\n",
            " 34%|███▍      | 333/972 [02:11<04:10,  2.55it/s]\u001b[A\n",
            " 34%|███▍      | 334/972 [02:11<04:09,  2.56it/s]\u001b[A\n",
            " 34%|███▍      | 335/972 [02:12<04:09,  2.56it/s]\u001b[A\n",
            " 35%|███▍      | 336/972 [02:12<04:08,  2.56it/s]\u001b[A\n",
            " 35%|███▍      | 337/972 [02:12<04:08,  2.56it/s]\u001b[A\n",
            " 35%|███▍      | 338/972 [02:13<04:07,  2.56it/s]\u001b[A\n",
            " 35%|███▍      | 339/972 [02:13<04:07,  2.56it/s]\u001b[A\n",
            " 35%|███▍      | 340/972 [02:14<04:07,  2.56it/s]\u001b[A\n",
            " 35%|███▌      | 341/972 [02:14<04:06,  2.56it/s]\u001b[A\n",
            " 35%|███▌      | 342/972 [02:14<04:06,  2.56it/s]\u001b[A\n",
            " 35%|███▌      | 343/972 [02:15<04:05,  2.56it/s]\u001b[A\n",
            " 35%|███▌      | 344/972 [02:15<04:05,  2.56it/s]\u001b[A\n",
            " 35%|███▌      | 345/972 [02:16<04:04,  2.56it/s]\u001b[A\n",
            " 36%|███▌      | 346/972 [02:16<04:04,  2.56it/s]\u001b[A\n",
            " 36%|███▌      | 347/972 [02:16<04:04,  2.56it/s]\u001b[A\n",
            " 36%|███▌      | 348/972 [02:17<04:03,  2.56it/s]\u001b[A\n",
            " 36%|███▌      | 349/972 [02:17<04:03,  2.56it/s]\u001b[A\n",
            " 36%|███▌      | 350/972 [02:17<04:02,  2.56it/s]\u001b[A\n",
            " 36%|███▌      | 351/972 [02:18<04:02,  2.56it/s]\u001b[A\n",
            " 36%|███▌      | 352/972 [02:18<04:02,  2.56it/s]\u001b[A\n",
            " 36%|███▋      | 353/972 [02:19<04:01,  2.56it/s]\u001b[A\n",
            " 36%|███▋      | 354/972 [02:19<04:01,  2.56it/s]\u001b[A\n",
            " 37%|███▋      | 355/972 [02:19<04:00,  2.56it/s]\u001b[A\n",
            " 37%|███▋      | 356/972 [02:20<04:00,  2.56it/s]\u001b[A\n",
            " 37%|███▋      | 357/972 [02:20<04:00,  2.56it/s]\u001b[A\n",
            " 37%|███▋      | 358/972 [02:21<03:59,  2.56it/s]\u001b[A\n",
            " 37%|███▋      | 359/972 [02:21<03:59,  2.56it/s]\u001b[A\n",
            " 37%|███▋      | 360/972 [02:21<03:59,  2.56it/s]\u001b[A\n",
            " 37%|███▋      | 361/972 [02:22<03:58,  2.56it/s]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Model and outputs**"
      ],
      "metadata": {
        "id": "m84tSeoBJmRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################################################\n",
        "torch.save(\n",
        "    model.state_dict(),\n",
        "    f\"checkpoint_path0_epoch{epoch+1:02d}.pth\"\n",
        ")\n",
        "# Save the losses\n",
        "np.save(\"train_losses_path0.npy\", train_losses)\n",
        "np.save(\"test_losses_path0.npy\", test_losses)\n",
        "np.save(\"mse_list_path0.npy\", mse_list)\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "total_dataset = MS2Dataset(precursor_df, matrix, max_length_input=max_length_input)\n",
        "total_loader = DataLoader(\n",
        "    total_dataset,\n",
        "    batch_size = batch_size,     # you may want to scale this up (e.g. 4×) now that you have 4 GPUs\n",
        "    shuffle    = False,\n",
        "    num_workers= 1,\n",
        "    pin_memory = True\n",
        ")\n",
        "with torch.no_grad():\n",
        "    for input_batch, _, output_pos_batch, _ in tqdm(total_loader):\n",
        "        # Move to GPU/CPU\n",
        "        input_batch      = input_batch.to(device)\n",
        "        output_pos_batch = output_pos_batch.to(device)\n",
        "\n",
        "        # 1) Forward pass\n",
        "        logits = model(input_batch)         # [B, L, 1]\n",
        "        probs  = torch.sigmoid(logits)      # [B, L, 1]\n",
        "        probs  = probs.squeeze(-1)          # [B, L]\n",
        "\n",
        "        B, L = probs.shape\n",
        "        # 2) build a [B,L] mask that picks out the output_length tokens after [OUTPUT]\n",
        "        positions = torch.arange(L, device=probs.device).unsqueeze(0)  # [1, L]\n",
        "        start     = (output_pos_batch.unsqueeze(1) + 1)               # [B, 1]\n",
        "        end       = start + output_length                             # [B, 1]\n",
        "        select_mask = (positions >= start) & (positions < end)        # [B, L]\n",
        "\n",
        "        # 3) for each sample i, pick its slice of length output_length\n",
        "        #    and stack them into a [B, output_length] tensor\n",
        "        batch_preds = torch.stack([\n",
        "            probs[i, select_mask[i]]\n",
        "            for i in range(B)\n",
        "        ], dim=0)  # [B, output_length]\n",
        "\n",
        "        all_preds.append(batch_preds.cpu())\n",
        "\n",
        "all_preds = torch.cat(all_preds, dim=0).numpy()\n",
        "# 5) save to file\n",
        "np.save(\"predictions_path0.npy\", all_preds)\n",
        "\n"
      ],
      "metadata": {
        "id": "3KiFoWt4FXvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up one figure per metric\n",
        "fig_l1, ax_l1 = plt.subplots()\n",
        "fig_mse, ax_mse = plt.subplots()\n",
        "\n",
        "ax_l1.plot(train_losses, label=\"Train L1\")\n",
        "ax_l1.plot(test_losses,  label=\"Test  L1\")\n",
        "ax_l1.set_title(\"L1 Loss\")\n",
        "ax_l1.legend()\n",
        "ax_l1.set_xlabel(\"Epoch\")\n",
        "ax_l1.set_ylabel(\"Loss\")\n",
        "ax_l1.grid()\n",
        "fig_l1.savefig(\"l1_loss_path0.png\")\n",
        "ax_mse.plot(mse_list, label=\"MSE\")\n",
        "ax_mse.set_title(\"Mean Squared Error\")\n",
        "ax_mse.legend()\n",
        "ax_mse.set_xlabel(\"Epoch\")\n",
        "ax_mse.set_ylabel(\"Loss\")\n",
        "ax_mse.grid()\n",
        "fig_mse.savefig(\"mse_path0.png\")"
      ],
      "metadata": {
        "id": "QWA36s74Jjkz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}